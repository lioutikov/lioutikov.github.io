[{"authors":["rudi"],"categories":null,"content":"Rudolf Lioutikov is an Assistant Professor of Practice at the University of Texas at Austin since 2019. He develops and teaches the Robot Learning Stream of the Freshmen Research Initiative. In addition, Rudolf is a Postdoctoral Fellow with the Personal Autonomous Robotics Lab, where he conducts research and develops new methods for areas such as robot learning, reinforcement learning, imitation learning and human-robot collaboration.\nBefore he joined the UT Computer Science Department, Rudolf worked as a Ph.D. candidate at the Intelligent Autonomous Systems Lab in Darmstadt. In his dissertation he developed an imitation learning pipeline which learns a library of movement primitives and a comprehensible behavior representation from unlabeled data.\nRudolf was warded his Ph.D. with distinction by the Technische Univerist√§t Darmstadt in 2018 and his dissertation was considered a finalist for the Georges Giralt PhD Award by the European Robotics Federation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"15450ae6cc271f698a70c57723db3af6","permalink":"https://www.cs.utexas.edu/~rudi/authors/rudi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/rudi/","section":"authors","summary":"Rudolf Lioutikov is an Assistant Professor of Practice at the University of Texas at Austin since 2019. He develops and teaches the Robot Learning Stream of the Freshmen Research Initiative. In addition, Rudolf is a Postdoctoral Fellow with the Personal Autonomous Robotics Lab, where he conducts research and develops new methods for areas such as robot learning, reinforcement learning, imitation learning and human-robot collaboration.\nBefore he joined the UT Computer Science Department, Rudolf worked as a Ph.","tags":null,"title":"Rudolf Lioutikov","type":"authors"},{"authors":null,"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"925a59053a051fd945b81b0348fc8d50","permalink":"https://www.cs.utexas.edu/~rudi/teaching/fri_rl_spring20/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/teaching/fri_rl_spring20/","section":"teaching","summary":"","tags":null,"title":"Robot Learning from Demonstration and Interaction (CS309)","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"ecb3daeb6a2887f6a064a410a717b9b5","permalink":"https://www.cs.utexas.edu/~rudi/teaching/fri_rl_fall19/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/teaching/fri_rl_fall19/","section":"teaching","summary":"","tags":null,"title":"Robot Learning from Demonstration and Interaction (CS378)","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"54da6c5bb099f1bdefe7bf4009131600","permalink":"https://www.cs.utexas.edu/~rudi/teaching/fri_rl_summer19/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/teaching/fri_rl_summer19/","section":"teaching","summary":"","tags":null,"title":"FRI Summer Fellowship: Robot Learning","type":"widget_page"},{"authors":["R. Lioutikov","G. Maeda","F.F. Veiga","K. Kersting","J. Peters"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"bdad40ed33a56e31649d9cf187dddd75","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovj-19/","publishdate":"2020-01-20T22:19:13.716135Z","relpermalink":"/publication/lioutikovj-19/","section":"publication","summary":"Movement Primitives are a well studied and widely applied concept in modern robotics. However, composing primitives out of an existing library has shown to be a challenging problem. We propose the use of probabilistic context-free grammars to sequence a series of primitives to generate complex robot policies from a given library of primitives. The rule-based nature of formal grammars allows an intuitive encoding of hierarchically structured tasks. This hierarchical concept strongly connects with the way robot policies can be learned, organized, and re-used. However, the induction of context-free grammars has proven to be a complicated and yet unsolved challenge.We exploit the physical nature of robot movement primitives to restrict and efficiently search the grammar space.The grammar is learned by applying a Markov chain Monte Carlo optimization over the posteriors of the grammars given the observations. The proposal distribution is defined as a mixture over the probabilities of the operators connecting the search space. Moreover, we present an approach for the categorization of probabilistic movement primitives and discuss how the connectibility of two primitives can be determined. These characteristics in combination with restrictions to the operators guarantee continuous sequences while reducing the grammar space.Additionally, a set of attributes and conditions is introduced that augments probabilistic context-free grammars in order to solve primitive sequencing tasks with the capability to adapt single primitives within the sequence. The method was validated on tasks that require the generation of complex sequences consisting of simple movement primitives using a 7 degree-of-freedom lightweight robotic arm.","tags":null,"title":"Learning Attribute Grammars for Movement Primitive Sequencing","type":"publication"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"1cc37d77783f58daf3a91c34920e33df","permalink":"https://www.cs.utexas.edu/~rudi/teaching/fri_rl_spring19/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/teaching/fri_rl_spring19/","section":"teaching","summary":"","tags":null,"title":"Robot Learning from Demonstration and Interaction (CS309)","type":"widget_page"},{"authors":["R.. Lioutikov","F. Faller","M. Sigg","J. Peters","G Maeda"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"ccde0db1cf28f316ab53a46cd7cef228","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovw-18-a/","publishdate":"2020-01-20T22:19:13.7215Z","relpermalink":"/publication/lioutikovw-18-a/","section":"publication","summary":"Demonstrating or pre-programming solutions to all possible tasks that a robot may encounter is unrealistic in scenarios that go beyond the structured industrial environment.Many tasks can be seen as sequences of simple sub-tasks. We propose an approach that allows robots to solve various tasks by sequencing elementary skills. These skills are represented by simple previously learned movement primitives. Each primitive only performs a limited action. Solutions for unseen problems are generated by combining these simple primitives into sequences, here using the A* graph search algorithm.","tags":null,"title":"A Graph-Search Based Approach for Movement Primitive Sequencing","type":"publication"},{"authors":["R. Lioutikov","G. Maeda","F.F. Veiga","K. Kersting","J. Peters"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"4ff0dab3a2af66adcca22e9b62a835fb","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovc-18/","publishdate":"2020-01-20T22:19:13.718151Z","relpermalink":"/publication/lioutikovc-18/","section":"publication","summary":"Movement Primitives are a well studied and widely applied concept in modern robotics. Composing primitives out of an existing library, however, has shown to be a challenging problem. We propose the use of probabilistic context-free grammars to sequence a series of primitives to generate complex robot policies from a given library of primitives. The rule-based nature of formal grammars allows an intuitive encoding of hierarchically and recursively structured tasks. This hierarchical concept strongly connects with the way robot policies can be learned, organized, and re-used. However,the induction of context-free grammars has proven to be a complicated and yet unsolved challenge. In this work, we exploit the physical nature of robot movement primitives to restrict and efficiently search the grammar space. The grammar is learned applying a Markov Chain Monte Carlo optimization over the posteriors of the grammars given the observations.The proposal distribution is defined as a mixture over the probabilities of the operators connecting the search space.Restrictions to these operators guarantee continuous sequences while reducing the grammar space. We validate our method on a redundant 7 degree-of-freedom lightweight robotic arm on tasks that require the generation of complex sequences consisting of simple movement primitives.","tags":null,"title":"Inducing Probabilistic Context-Free Grammars for the Sequencing of Robot Movement Primitives","type":"publication"},{"authors":["R.. Lioutikov","G. Maeda","F.F. Veiga","K. Kersting","J Peters"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"dc06fb573b7760abae1e1b6ec1279f44","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovw-18-b/","publishdate":"2020-01-20T22:19:13.721785Z","relpermalink":"/publication/lioutikovw-18-b/","section":"publication","summary":"Movement Primitives are a well studied and widely applied concept in modern robotics. Composing primitives out of an existing library, however, has shown to be a challenging problem. We propose probabilistic context-free grammars to sequence a series of primitives to generate complex robot policies from a given library of primitives. The rule-based nature of formal grammars allows an intuitive encoding of hierarchically and recursively structured tasks. This hierarchical concept strongly connects with the way robot policies can be learned, organized, and re-used. The induction of context-free grammars is often formulated as a maximum a-posteriori optimization. Given the common formulation of the prior,the resulting grammars are often not easily comprehensible by non-experts. We introduce a novel, easy to tune prior aimed at producing intuitive grammars for movement primitive sequencing.","tags":null,"title":"Learning Intuitive Grammars for Movement Primitive Sequences","type":"publication"},{"authors":["R.. Lioutikov","J Peters"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"d9604b4cb1ec02489732d542aa0fb74f","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovw-18-c/","publishdate":"2020-01-20T22:19:13.722067Z","relpermalink":"/publication/lioutikovw-18-c/","section":"publication","summary":"In this work we propose attribute grammars as a mechanism to sequence movement primitives. Attribute grammars extend probabilistic context-free grammars by introducing attributes and conditions to the grammar symbols and rules. We show how such grammars can be applied to solve complex tasks by sequencing simpler subtasks. Each subtask is represented as movement primitive and the main task is solved by a sequence of primitives. By defining a general set of attributes and a corresponding evaluation scheme we introduce a general framework to transform probabilistic context-free grammars for movement primitive sequencing tasks to attribute grammars. We apply an attribute grammar to solve the task of picking and placing a stone in a game of tic-tac-toe.","tags":null,"title":"Movement Primitive Sequencing via Attribute Grammars","type":"publication"},{"authors":["R. Lioutikov"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"347f5922c410be25509838bb3fe9b85e","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovt-18/","publishdate":"2020-01-20T22:19:13.715379Z","relpermalink":"/publication/lioutikovt-18/","section":"publication","summary":"Robots are becoming an ever bigger part of our day to day life. They take up simple tasks in households, like vacuum cleaning and lawn mowing. They ensure a steady and reliable process at many work places in large scale manufacturing, like the automotive and electronics industry. Furthermore, robots are becoming more and more socially accepted, for instance as autonomous drivers. They even start to engage in special and elderly care, aiming to fill a void created by a rapidly aging population. Additionally, the increasing complexity and capability of robotic systems allows to solve ever more complicated tasks in increasingly difficult scenarios and environments. Soon, encountering and interacting with robots will be considered as natural as interacting with other humans.\nHowever, when it comes to defining and understanding the behavior of robots, experts are still necessary. Robots usually follow predefined routines which are programmed and tuned by people with years of experience. Unintended behavior is traced back to a certain part of the source code which can be modified using a specific programming language. Most of the people that will interact with robotic servants or coworkers in the future, will not have the necessary skill set to instruct robots in such detail. This need for an expert represents a significant bottleneck to the deployment of robots as our everyday companion in households and at work. This thesis presents several novel approaches aiming at facilitating the interaction between non-expert humans and robots in terms of intuitive instruction and simple understanding of the robot capabilities with respect to a given task.\nChapter 3 introduces a novel method that segments unlabeled demonstrations into sequence of movement primitives while simultaneously learning a movement primitive library. This method allows the non-expert to teach an entire task rather than every single primitive. Movement primitives represent a simple, atomic and commonly parameterized motion. The presented method segments each demonstration by identifying similar patterns across all demonstrations and treating them as samples drawn from a learned probabilistic representation of a movement primitive. The method is formulated as an expectation-maximization approach and was evaluated in several tasks,including a chair assembly and segmenting table tennis demonstrations.\nIn Chapter 4 the previously segmented demonstrations and the learned primitive library are used to induce a formal grammar for movements. Formal grammars are a well established concept in formal language theory and have been applied in several fields, reaching from linguistics, over compiler architecture to robotics. The simplest class of grammars, regular grammars, correspond in their probabilistic form to Hidden Markov Models. However, the intuitive, hierarchical representation of transitions as a set of rules makes it easier for non-experts to comprehend the possible behaviors the grammar implies. A sequence of movements can now be considered a sentence produced by the learned grammar. The production of each sentence can be illustrated by a tree structure, allowing an easy understanding of the involved rules. Probabilistic context-free grammars are a superset of regular grammars and, hence, are more expressive and exceed the capabilities of Hidden Markov Models. While the induction of probabilistic context-free grammars is considered a difficult, unsolved problem for natural languages, the observed sequences of movement primitives show much simpler structures, making the induction more feasible. The method was successfully evaluated on several tasks, such as a pick-and-place task in a tic-tac-toe setting or a handover task in a collaborative tool box assembly.\nChapter 5 introduces the concept of reinforcement learning into the domain of formal grammars. Given an objective, we apply a natural policy gradient approach in order to learn the grammar parameters that produces sequences of primitives that solve that objective. This allows the autonomous improvement of robot behavior. For instance, a cleaning up task can be optimized for efficiency while avoiding self collisions. The parameters of the grammar are the probabilities of each production. Therefore, probability constraints have to be maintained while learning the parameters. The applied natural policy gradient method ensures reasonably small parameter updates, such that the grammar probabilities change gradually. We derive the natural policy gradient method for formal grammars and evaluate the method on several tasks.\nTogether, the individual contributions presented in this thesis form an imitation learning pipeline that facilitates the instruction, interaction and collaboration with robots. Starting from unlabeled demonstrations, an underlying movement primitive library is learned while simultaneously segmenting the given demonstrations into sequences of primitives. These sequences are than used to induce a formal grammar. The structure of the grammar and the produced parse trees form a comprehensible representation of the robot capabilities with respect to the demonstrated task. Finally, a reinforcement learning approach allows the autonomous optimization of the grammar given an objective.","tags":null,"title":"Parsing Motion and Composing Behavior for Semi-Autonomous Manipulation","type":"publication"},{"authors":["D. Wilbers","R. Lioutikov","J. Peters"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"f46fff652c20d3bf7d667a7ae83eef17","permalink":"https://www.cs.utexas.edu/~rudi/publication/wilbersc-17/","publishdate":"2020-01-20T22:19:13.718462Z","relpermalink":"/publication/wilbersc-17/","section":"publication","summary":"Human like robot skills, e.g., cleaning a table or handing over a plate, can often be generalized to different task variations. Usually, these are start-/goal position, and trained environment changes. We investigate how to modify motion primitives to context changes, which are not included in the training data. Specifically, we focus on maintaining human like motion characteristics and generalizability, while adapting to unseen context. Therefore, we present an optimization technique, which maximizes the expected return and minimizes the Kullback-Leibler Divergence to the demonstrations at the same time. Simultaneously, our algorithm learns how to linearly combine the adapted primitive with the demonstrations, such that only relevant parts of the primitive are adapted. We evaluate our approach in obstacle avoidance and broken joint scenarios in simulation, as well as on a real robot.","tags":null,"title":"Context-Driven Movement Primitive Adaptation","type":"publication"},{"authors":["T. Osa","E. A. M. Ghalamzan","R. Stolkin","R. Lioutikov","J. Peters","G. Neumann"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"14ad2335c723d200350a1ed33fb64ac2","permalink":"https://www.cs.utexas.edu/~rudi/publication/osaj-17/","publishdate":"2020-01-20T22:19:13.717172Z","relpermalink":"/publication/osaj-17/","section":"publication","summary":"Trajectory optimization is an essential tool for motion planning under multiple constraints of robotic manipulators.Optimization-based methods can explicitly optimize a trajectory by leveraging prior knowledge of the system and have been used in various applications such as collision avoidance. However, these methods often require a hand-coded cost function in order to achieve the desired behavior. Specifying such cost function for a complex desired behavior, e.g., disentangling a rope, is a non-trivial task that is often even infeasible. Learning from demonstration (LfD) methods offer an alternative way to program robot motion. LfD methods are less dependent on analytical models and instead learn the behavior of experts implicitly from the demonstrated trajectories. However, the problem of adapting the demonstrations to new situations, e.g., avoiding newly introduced obstacles, has not been fully investigated in the literature. In this paper, we present a motion planning framework that combines the advantages of optimization-based and demonstration-based methods. We learn a distribution of trajectories demonstrated by human experts and use it to guide the trajectory optimization process. The resulting trajectory maintains the demonstrated behaviors, which are essential to performing the task successfully,while adapting the trajectory to avoid obstacles. In simulated experiments and with a real robotic system, we verify that our approach optimizes the trajectory to avoid obstacles and encodes the demonstrated behavior in the resulting trajectory.","tags":null,"title":"Guiding Trajectory Optimization by Demonstrated Distributions","type":"publication"},{"authors":["R. Lioutikov","G. Neumann","G. Maeda","J. Peters"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"2506c5910e5fcc46a47201e4119ba213","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovj-17/","publishdate":"2020-01-20T22:19:13.715805Z","relpermalink":"/publication/lioutikovj-17/","section":"publication","summary":"Movement primitives are a well established approach for encoding and executing movements. While the primitives themselves have been extensively researched, the concept of movement primitive libraries has not received similar attention. Libraries of movement primitives represent the skill set of an agent. Primitives can be queried and sequenced in order to solve specific tasks. The goal of this work is to segment unlabeled demonstrations into a representative set of primitives. Our proposed method differs from current approaches by taking advantage of the often neglected,mutual dependencies between the segments contained in the demonstrations and the primitives to be encoded. By exploiting this mutual dependency, we show that we can improve both the segmentation and the movement primitive library. Based on probabilistic inference our novel approach segments the demonstrations while learning a probabilistic representation of movement primitives. We demonstrate our method on two real robot applications. First, the robot segments sequences of different letters into a library, explaining the observed trajectories. Second, the robot segments demonstrations of a chair assembly task into a movement primitive library. The library is subsequently used to assemble the chair in an order not present in the demonstrations.","tags":null,"title":"Learning Movement Primitive Libraries through Probabilistic Segmentation","type":"publication"},{"authors":["G. Maeda","M. Ewerton","G. Neumann","R. Lioutikov","J. Peters"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"357dacb49da7568d59f85c901e5d5a1a","permalink":"https://www.cs.utexas.edu/~rudi/publication/maedaj-17-b/","publishdate":"2020-01-20T22:19:13.716449Z","relpermalink":"/publication/maedaj-17-b/","section":"publication","summary":"This paper proposes a method to achieve fast and fluid human-robot interaction by estimating the progress of the movement of the human. The method allows the progress, also referred to as the phase of the movement,to be estimated even when observations of the human are partial and occluded; a problem typically found when using motion capture systems in cluttered environments. By leveraging on the framework of Interaction Probabilistic Movement Primitives (ProMPs), phase estimation makes it possible to classify the human action, and to generate a corresponding robot trajectory before the human finishes his/her movement. The method is therefore suited for semi-autonomous robots acting as assistants and coworkers. Since observations may be sparse, our method is based on computing the probability of different phase candidates to find the phase that best aligns the Interaction ProMP with the current observations. The method is fundamentally different from approaches based on Dynamic Time Warping (DTW) that must rely on a consistent stream of measurements at runtime. The phase estimation algorithm can be seamlessly integrated into Interaction ProMPs such that robot trajectory coordination, phase estimation, and action recognition can all be achieved in a single probabilistic framework. We evaluated the method using a 7-DoF lightweight robot arm equipped with a 5-finger hand in single and multi-task collaborative experiments. We compare the accuracy achieved by phase estimation with our previous method based on DTW.","tags":null,"title":"Phase Estimation for Fast Action Recognition and Trajectory Generation in Human-Robot Collaboration","type":"publication"},{"authors":["G. Maeda","G. Neumann","M. Ewerton","R. Lioutikov","O. Kroemer","J. Peters"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"58499d3b37bff3acf6abc69c1a50bca1","permalink":"https://www.cs.utexas.edu/~rudi/publication/maedaj-17-a/","publishdate":"2020-01-20T22:19:13.716804Z","relpermalink":"/publication/maedaj-17-a/","section":"publication","summary":"This paper proposes an interaction learning method for collaborative and assistive robots based on movement primitives. The method allows for both action recognition and human-robot movement coordination. It uses imitation learning to construct a mixture model of human-robot interaction primitives. This probabilistic model allows the assistive trajectory of the robot to be inferred from human observations. The method is scalable in relation to the number of tasks and can learn nonlinear correlations between the trajectories that describe the human-robot interaction. We evaluated the method experimentally with a lightweight robot arm in a variety of assistive scenarios, including the coordinated handover of a bottle to a human, and the collaborative assembly of a toolbox. Potential applications of the method are personal caregiver robots,control of intelligent prosthetic devices, and robot coworkers in factories.","tags":null,"title":"Probabilistic Movement Primitives for Coordination of Multiple Human-Robot Collaborative Tasks","type":"publication"},{"authors":["A. Paraschos","R. Lioutikov","J. Peters","G. Neumann"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"49dface1021ac2542c5c9c20094a34b7","permalink":"https://www.cs.utexas.edu/~rudi/publication/paraschosj-17/","publishdate":"2020-01-20T22:19:13.717518Z","relpermalink":"/publication/paraschosj-17/","section":"publication","summary":"Movement  prioritization  is  a  common  approach to combine controllers of different tasks for redundant robots,where  each  task  is  assigned  a  priority.  The  priorities  of  the tasks  are  often  hand-tuned  or  the  result  of  an  optimization,but seldomly learned from data. This paper combines Bayesian task  prioritization  with  probabilistic  movement  primitives  to prioritize  full  motion  sequences  that  are  learned  from  demonstrations.   Probabilistic   movement   primitives   (ProMPs)   can encode  distributions  of  movements  over  full  motion  sequences and  provide  control  laws  to  exactly  follow  these  distributions.The probabilistic formulation allows for a natural application of Bayesian task prioritization. We extend the ProMP controllers with  an  additional  feedback  component  that  accounts  inaccuracies  in  following  the  distribution  and  allows  for  a  more robust  prioritization  of  primitives.  We  demonstrate  how  the task  priorities  can  be  obtained  from  imitation  learning  and how different primitives can be combined to solve even unseen task-combinations. Due to the prioritization, our approach can efficiently learn a combination of tasks without requiring individual models per task combination. Further, our approach can adapt  an  existing  primitive  library  by  prioritizing  additional controllers,  for  example,  for  implementing  obstacle  avoidance.Hence,  the  need  of  retraining  the  whole  library  is  avoided  in many cases. We evaluate our approach on reaching movements under constraints with redundant simulated planar robots and two physical robot platforms, the humanoid robot ‚ÄúiCub‚Äù and a  KUKA  LWR  robot  arm.","tags":null,"title":"Probabilistic Prioritization of Movement Primitives","type":"publication"},{"authors":["G. Maeda","A. Maloo","M. Ewerton","R. Lioutikov","J. Peters"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"a79b2c1ffdc92a20be7bdda9e7fe5821","permalink":"https://www.cs.utexas.edu/~rudi/publication/maedac-16/","publishdate":"2020-01-20T22:19:13.718781Z","relpermalink":"/publication/maedac-16/","section":"publication","summary":"This paper introduces our initial investigation on the problem of providing a semi-autonomous robot collaborator with anticipative capabilities to predict human actions. Anticipative robot behavior is a desired characteristic of robot collaborators that lead to fluid, proactive interactions. We are particularly interested in improving reactive methods that rely on human action recognition to activate the corresponding robot action. Action recognition invariably causes delay in the robot‚Äôs response, and the goal of our method is to eliminate this delay by predicting the next human action. Prediction is achieved by using a lookup table containing variations of assembly sequences, previously demonstrated by different users. The method uses the nearest neighbor sequence in the table that matches the actual sequence of human actions. At the movement level, our method uses a probabilistic representation of interaction primitives to generate robot trajectories. The method is demonstrated using a 7 degree-of-freedom lightweight arm equipped with a 5-finger hand on an assembly task consisting of 17 steps.","tags":null,"title":"Anticipative Interaction Primitives for Human-Robot Collaboration","type":"publication"},{"authors":["D. Koert","G. Maeda","R. Lioutikov","G. Neumann","J. Peters"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"70d76e763d1accffb6b8104b1a36e865","permalink":"https://www.cs.utexas.edu/~rudi/publication/koertc-16/","publishdate":"2020-01-20T22:19:13.719098Z","relpermalink":"/publication/koertc-16/","section":"publication","summary":"Learning motions from human demonstrations provides an intuitive way for non-expert users to teach tasks to robots. In particular, intelligent robotic co-workers should not only mimic human demonstrations but should also be able to adapt them to varying application scenarios. As such,robots must have the ability to generalize motions to different workspaces, e.g. to avoid obstacles not present during original demonstrations. Towards this goal our work proposes a unified method to (1) generalize robot motions to different workspaces,using a novel formulation of trajectory optimization that explicitly incorporates human demonstrations, and (2) to locally adapt and reuse the optimized solution in the form of a distribution of trajectories. This optimized distribution can be used, online, to quickly satisfy via-points and goals of a specific task. We validate the method using a 7 degrees of freedom (DoF)lightweight arm that grasps and places a ball into different boxes while avoiding obstacles that were not present during the original human demonstrations.","tags":null,"title":"Demonstration Based Trajectory Optimization for Generalizable Robot Motions","type":"publication"},{"authors":["G. Maeda","A. Maloo","M. Ewerton","R. Lioutikov","J Peters"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"2c5407453009230e09550c74ecfd5886","permalink":"https://www.cs.utexas.edu/~rudi/publication/maedaw-16/","publishdate":"2020-01-20T22:19:13.722341Z","relpermalink":"/publication/maedaw-16/","section":"publication","summary":"This paper introduces our initial investigation into the problem of providing a semi-autonomous robot collaborator with anticipative capabilities to predict the upcoming human actions. Predictive robot behavior is a desired characteristic of robot collaborators that lead to fluid and faster interactions. We are particularly interested in improving reactive methods that rely on human action recognition to activate a corresponding robot movement. Action recognition invariably causes delay in the robot‚Äôs response, and the goal of our method is to minimize this delay by predicting the next human action and pre-triggering the corresponding robot motions. The prediction is achieved by using a lookup table containing variations of assembly sequences, previously demonstrated by different users.The method uses the nearest neighbor sequence in the table that matches the actual sequence of human actions. At the movement level, our method uses a probabilistic representation of interaction primitives to generate the robot trajectories. The method is demonstrated using a 7 degree-of-freedom lightweight(DoF) arm equipped with a 5-finger hand on an assembly task consisting of 17 steps.","tags":null,"title":"Proactive Human-Robot Collaboration with Interaction Primitives","type":"publication"},{"authors":["G. Maeda","G. Neumann","M. Ewerton","R. Lioutikov","J. Peters"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"90eb13364d4af2c30b593c87ad4e941f","permalink":"https://www.cs.utexas.edu/~rudi/publication/maedac-15/","publishdate":"2020-01-20T22:19:13.720018Z","relpermalink":"/publication/maedac-15/","section":"publication","summary":"This paper proposes an interaction learning method suited for semi-autonomous robots that work with or assist a human partner. The method aims at generating a collaborative trajectory of the robot as a function of the current action of the human. The trajectory generation is based on action recognition and prediction of the human movement given intermittent observations of his/her positions under unknown speeds of execution;a problem typically found when using motion capture systems in scenarios that lead to occlusion. Of particular interest, the ability to predict the human movement while observing the initial part of his/her trajectory allows for faster robot reactions, and as it will be shown, also eliminates the need of time-alignment of the training data. The method models the coupling be-tween human-robot movement primitives and is scalable in relation to the number of tasks. We evaluated the method using a 7-DoF lightweight robot arm equipped with a 5-finger hand in a multi-task collaborative assembly experiment, also comparing results with our previous method based on time-aligned trajectories.","tags":null,"title":"A Probabilistic Framework for Semi-Autonomous Robots Based on Interaction Primitives with Phase Estimation","type":"publication"},{"authors":["M. Ewerton","G. Neumann","R. Lioutikov","H. Ben Amor","J. Peters","G. Maeda"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"fd3b3677034e02753e86fdd5948d3c38","permalink":"https://www.cs.utexas.edu/~rudi/publication/ewertonc-15/","publishdate":"2020-01-20T22:19:13.719403Z","relpermalink":"/publication/ewertonc-15/","section":"publication","summary":"Robots that interact with humans must learn to not only adapt to different human partners but also to new interactions. Such a form of learning can be achieved by demonstrations and imitation. A recently introduced method to learn interactions from demonstrations is the framework of Interaction Primitives. While this framework is limited to represent and generalize a single interaction pattern, in practice, interactions between a human and a robot can consist of many different patterns. To overcome this limitation this paper proposes a Mixture of Interaction Primitives to learn multiple interaction patterns from unlabeled demonstrations.Specifically the proposed method uses Gaussian Mixture Mod-els of Interaction Primitives to model nonlinear correlations between the movements of the different agents. We validate our algorithm with two experiments involving interactive tasks between a human and a lightweight robotic arm. In the first,we compare our proposed method with conventional Interaction Primitives in a toy problem scenario where the robot and the human are not linearly correlated. In the second, we present a proof-of-concept experiment where the robot assists a human in assembling a box.","tags":null,"title":"Learning Multiple Collaborative Tasks with a Mixture of Interaction Primitives","type":"publication"},{"authors":["E. Rueckert","R. Lioutikov","R. Calandra","M. Schmidt","P. Beckerle","J. Peters"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"604b5e871644a9f083f0e2d9bd63d900","permalink":"https://www.cs.utexas.edu/~rudi/publication/rueckertw-15/","publishdate":"2020-01-20T22:19:13.722634Z","relpermalink":"/publication/rueckertw-15/","section":"publication","summary":"Sensor gloves are popular input devices for a large variety of applications including health monitoring, control of music instruments, learning sign language, dexterous computer interfaces, and teleoperating robot hands. Many commercial products as well as low-cost open source projects have been developed.1We discuss here how low-cost (approx.250EUROs)sensor gloves with force feedback can be build, provide an open source software interface for Matlab and present first results in learning object manipulation skills through imitation learning on the humanoid robot iCub.","tags":null,"title":"Low-cost Sensor Glove with Force Feedback for Learning from Demonstrations using Probabilistic Trajectory Representations","type":"publication"},{"authors":["A. Abdolmaleki","R. Lioutikov","J Peters","N. Lau","L. Reis","G. Neumann"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"cc096d811e61c5d19aa07dd03e872aeb","permalink":"https://www.cs.utexas.edu/~rudi/publication/abdolmalekic-15/","publishdate":"2020-01-20T22:19:13.720323Z","relpermalink":"/publication/abdolmalekic-15/","section":"publication","summary":"Stochastic search algorithms are general black-box optimizers. Due to their ease of use and their generality, they have recently also gained a lot of attention in operations research, machine learning and policy search. Yet, these algorithms require a lot of evaluations of the objective, scale poorly with the problem dimension, are affected by highly noisy objective functions and may converge prematurely. To alleviate these problems, we introduce a new surrogate-based stochastic search approach. We learn simple, quadratic surrogate models of the objective function.As the quality of such a quadratic approximation is limited, we do not greedily exploit the learned models. The algorithm can be misled by an inaccurate optimum introduced by the surrogate. Instead, we use information theoretic constraints to bound the ‚Äòdistance‚Äô between the new and old data distribution while maximizing the objective function. Additionally the new method is able to sustain the exploration of the search distribution to avoid premature convergence. We compare our method with state of art black-box optimization methods on standard unimodal and multi-modal optimization functions, on simulated planar robot tasks and a complex robot ball throwing task. The proposed method considerably outperforms the existing approaches.","tags":null,"title":"Model-Based Relative Entropy Stochastic Search","type":"publication"},{"authors":["R. Lioutikov","G. Neumann","G. Maeda","J. Peters"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"0eb0226f9b688ebda12ca6bb2b768d9c","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovc-15/","publishdate":"2020-01-20T22:19:13.719719Z","relpermalink":"/publication/lioutikovc-15/","section":"publication","summary":"Movement primitives are a well established approach for encoding and executing robot movements. While the primitives themselves have been extensively researched, the concept of movement primitive libraries has not received as much attention. Libraries of movement primitives represent the skill set of an agent and can be queried and sequenced in order to solve specific tasks. The goal of this work is to segment unlabeled demonstrations into an optimal set of skills. Our novel approach segments the demonstrations while learning a probabilistic representation of movement primitives. The method differs from current approaches by taking advantage of the often neglected, mutual dependencies between the segments contained in the demonstrations and the primitives to be encoded. Therefore, improving the combined quality of both segmentation and skill learning. Furthermore, our method allows incorporating domain specific insights using heuristics, which are subsequently evaluated and assessed through probabilistic inference methods. We demonstrate our method on a real robot application, where the robot segments demonstrations of a chair assembly task into a skill library. The library is subsequently used to assemble the chair in an order not present in the demonstrations.","tags":null,"title":"Probabilistic Segmentation Applied to an Assembly Task","type":"publication"},{"authors":["M. Lopes","J. Peters","J. Piater","M. Toussaint","A. Baisero","B. Busch","O. Erkent","O. Kroemer","R. Lioutikov","G. Maeda","Y. Mollard","T. Munzer","D. Shukla"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"8d3b553932f031a5eb54e52a207e0e28","permalink":"https://www.cs.utexas.edu/~rudi/publication/lopesw-2015/","publishdate":"2020-01-20T22:19:13.722918Z","relpermalink":"/publication/lopesw-2015/","section":"publication","summary":"We present the principles, current work and plans for the EU-FP7 Project Semi Autonomous 3rd-Hand Robot. In this project, we pursue a breakthrough inflexible manufacturing by developing a symbiotic robot assistant that acts as a third hand of a human worker. It will be straight forward to instruct even by untrained workers and allow for efficient knowledge transfer between tasks. We demonstrate its efficiency in the collaborative assembly of furniture.","tags":null,"title":"Semi-Autonomous 3rd-Hand Robot","type":"publication"},{"authors":["R. Lioutikov","A. Paraschos","J. Peters","G. Neumann"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"3801f2f35327909579fe092d002fd008","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovj-14/","publishdate":"2020-01-20T22:19:13.717837Z","relpermalink":"/publication/lioutikovj-14/","section":"publication","summary":"Stochastic Optimal Control (SOC) is typically used to plan a movement for a specific situation. While most SOC methods fail to generalize this movement plan to a new situation without re-planning, we present a SOC method that allows us to reuse the obtained policy in a new situation as the policy is more robust to slight deviations from the initial movement plan. In order to improve the robustness of the policy, we employ information-theoretic policy updates that explicitly operate on trajectory distributions instead of single trajectories. To ensure a stable and smooth policy update, we limit the ‚Äòdistance‚Äô between the trajectory distributions of the old and the new control policy. The introduced bound offers a closed form solution for the resulting policy and extends results from recent developments in SOC. Indifference to many standard SOC algorithms, our approach can directly infer the system dynamics from data points, and, hence, can also be used for model-based reinforcement learning.","tags":null,"title":"Generalizing Movements with Information Theoretic Stochastic Optimal Control","type":"publication"},{"authors":["G. Maeda","M. Ewerton","R. Lioutikov","H. Ben Amor","J. Peters","G. Neumann"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"106dd0a6ee9f1aa496780c1c7c35c508","permalink":"https://www.cs.utexas.edu/~rudi/publication/maedac-14/","publishdate":"2020-01-20T22:19:13.72091Z","relpermalink":"/publication/maedac-14/","section":"publication","summary":"This paper proposes a probabilistic framework based on movement primitives for robots that work in collaboration with a human coworker. Since the human coworker can execute a variety of unforeseen tasks a requirement of our system is that the robot assistant must be able to adapt and learn new skills on-demand, without the need of an expert programmer. Thus, this paper leverages on the framework of imitation learning and its application to human-robot interaction using the concept of Interaction Primitives (IPs).We introduce the use of Probabilistic Movement Primitives(ProMPs) to devise an interaction method that both recognizes the action of a human and generates the appropriate movement primitive of the robot assistant. We evaluate our method on experiments using a lightweight arm interacting with a human partner and also using motion capture trajectories of two humans assembling a box. The advantages of ProMPs in relation to the original formulation for interaction are exposed and compared.","tags":null,"title":"Learning Interaction for Collaborative Tasks with Probabilistic Movement Primitives","type":"publication"},{"authors":["R. Lioutikov","O. Kroemer","G. Maeda","J Peters"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"15896c57a4a69b600bdb0b14050c8a4c","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovc-14-a/","publishdate":"2020-01-20T22:19:13.720624Z","relpermalink":"/publication/lioutikovc-14-a/","section":"publication","summary":"Learning to perform complex tasks out of a sequence of simple small demonstrations is a key ability for more flexible robots. In this paper, we present a system that allows for the acquisition of such task executions based on dynamical movement primitives (DMPs). DMPs are a successful approach to encode and generalize robot movements. However,current applications involving DMPs mainly explore movements that,although challenging in terms of dexterity and dimensionality, usually comprise a single continuous movement. This article describes the implementation of a novel system that allows sequencing of simple demonstrations, each one encoded by its own DMP, to achieve a bimanual manipulation task that is too complex to be demonstrated with a single teaching action. As the experimental results show, the resulting system can successfully accomplish a sequenced task of grasping, placing and cutting a vegetable using a setup of a bimanual robot.","tags":null,"title":"Learning Manipulation by Sequencing Motor Primitives with a Two-Armed Robot","type":"publication"},{"authors":["M. Ewerton","G. Neumann","R. Lioutikov","H. Ben Amor","J. Peters","G Maeda"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"336d900b6fa60f161a2513f52cf61263","permalink":"https://www.cs.utexas.edu/~rudi/publication/ewertonw-14/","publishdate":"2020-01-20T22:19:13.723505Z","relpermalink":"/publication/ewertonw-14/","section":"publication","summary":"The task of physically assisting humans requires from robots the ability to adapt in many different ways: to changes in space of the human movement, to changes in the speed of the human, to changes in the environment, etc. This paper presents recent research on teaching robots how to interact with humans and to adapt to different circumstances.The approach presented here is based on Imitation Learning and Probabilistic Movement Representations. In particular, this paper explains the concept of a Mixture of Interaction Primitives to learn interactions from multiple unlabeled demonstrations and to deal with nonlinear correlations between the interacting partners. Furthermore, a method to compute reactions to human movements executed at different speeds is presented. A number of experiments with a lightweight robotic arm illustrate applications of the presented methods.","tags":null,"title":"Modeling Spatio-Temporal Variability in Human-Robot Interaction with Probabilistic Movement Primitives","type":"publication"},{"authors":["R. Lioutikov","A. Paraschos","J. Peters","G. Neumann"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"b98860ad8fc9dceeb67b7e816b624a85","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovc-2014-b/","publishdate":"2020-01-20T22:19:13.721211Z","relpermalink":"/publication/lioutikovc-2014-b/","section":"publication","summary":"Many Stochastic Optimal Control (SOC) approaches rely on samples to either obtain an estimate of the value function or a linearisation of the underlying system model.However, these approaches typically neglect the fact that the accuracy of the policy update depends on the closeness of the resulting trajectory distribution to these samples. The greedy operator does not consider such closeness constraint to the samples. Hence, the greedy operator can lead to oscillations or even instabilities in the policy updates. Such undesired behaviour is likely to result in an inferior performance of the estimated policy. We reuse inspiration from the reinforcement learning community and relax the greedy operator used in SOC with an information theoretic bound that limits the ‚Äòdistance‚Äô of two subsequent trajectory distributions in a policy update. The introduced bound ensures a smooth and stable policy update.Our method is also well suited for model-based reinforcement learning, where we estimate the system dynamics model from data. As this model is likely to be inaccurate, it might be dangerous to exploit the model greedily. Instead, our bound ensures that we generate new data in the vicinity of the current data, such that we can improve our estimate of the system dynamics model. We show that our approach outperforms several state of the art approaches on challenging simulated robot control tasks.","tags":null,"title":"Sample-Based Information-Theoretic Stochastic Optimal Control","type":"publication"},{"authors":["R. Lioutikov","O. Kroemer","J. Peters","G Maeda"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"36fb5ec5af4b0d12bc81b4406f4d129e","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovw-14/","publishdate":"2020-01-20T22:19:13.723227Z","relpermalink":"/publication/lioutikovw-14/","section":"publication","summary":"Robots in industrial manufacturing are usually programmed to repeatedly perform a fixed set of movements in an identical manner. However, rapidly changing product lines and the need for fast development and prototyping of new products combined with the expensive re-programming of such robots, demand a paradigm shift in industrial robotics. Robots in modern industry have to perform multiple tasks and must adapt to dynamic environments and change sin the executed task. In addition robots should be able to learn from human demonstrations in order to eliminate the costs of re-programming. Ideally the instructor should be allowed to teach the robot similarly to a novice co-worker. By teaching the robot personally, the robot adapts to the specific work flow of the worker and actively increases the productivity, thus the robot would act as a personalized assistant.","tags":null,"title":"Towards a Third Hand","type":"publication"},{"authors":["R. Lioutikov"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"7e825e7bb096aa75c83a4b30aa053859","permalink":"https://www.cs.utexas.edu/~rudi/publication/lioutikovt-13/","publishdate":"2020-01-20T22:19:13.715379Z","relpermalink":"/publication/lioutikovt-13/","section":"publication","summary":"Stochastic Optimal Control (SOC) is typically used to plan a movement for a specific situation. However, most SOC methods are not able to generalize the movement plan to a new situation, and, hence, replanning is required. In this paper we present a SOC method that allows us for reusing the controller in a new situation as it is more robust to deviations from the initial movement plan.In order to improve the robustness of the controller, we employ an information-theoretic policy update which explicitly operates on trajectory distributions instead of single trajectories. Our information theoretic policy update limits the ‚Äòdistance‚Äô between the trajectory distributions of the old and the new control policy and ensures a stable and smooth policy update. The introduced bound offers a closed form solution for the resulting policy and extends results from recent developments in SOC. In difference to many standard SOC algorithms, our approach can directly infer the system dynamics from data points, and, hence, can also be used for model-based reinforcement learning.","tags":null,"title":"Learning time-dependent Feedback Policies with Model-Based Policy Search","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://www.cs.utexas.edu/~rudi/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"","tags":null,"title":"Research","type":"widget_page"}]